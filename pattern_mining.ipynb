{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from elbow import KElbow\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.6 ms\n"
     ]
    }
   ],
   "source": [
    "class Binner():\n",
    "    \"\"\"Turn continuous data into discrete data using KMeans and find patterns in a subset of data above a threshold using FP Growth\n",
    "    Attributes\n",
    "    ----------\n",
    "    models_ : dictionary, (column name -> model)\n",
    "        Dictionary mapping a column to a KMeans model\n",
    "    number_of_bins_range_ : tuple, \n",
    "        The range of values for number of bins to try, the algorithm will automatically \n",
    "        select the best one from the range (default: (2,10)).\n",
    "    minimal_support_rate_ : float\n",
    "        A float between 0 and 1 for minimum support of the itemsets returned\n",
    "    threshold_ : float\n",
    "        The threshold to use for the conditon: support_rate(full data) * threshold < support_rate(subset)\n",
    "    full_df_ : pandas dataframe object\n",
    "        the full dataset we are using for patterns\n",
    "    subset_df_ : pandas dataframe object\n",
    "        the subset dataset we are using for patterns\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    This class has many helper functions, which can be used out of the box as well. You can create bins for a single column using `create_bins` and \n",
    "    find patterns for a dataset using `find_patterns`. The main function is `get_best_subset_patterns`, which finds the best patterns in a subset \n",
    "    of data when compared to the full dataset using support rates. The groups for the different binned columns can be accessed from self.models_\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> import seaborn as sns\n",
    "    >>> iris = sns.load_dataset('iris')\n",
    "    >>> titanic = sns.load_dataset('titanic')\n",
    "    >>> binner = Binner()\n",
    "    >>> binned_values_iris_petal_length = binner.create_bins('petal_length', iris, number_of_bins_range=(2,10), verbose=True)\n",
    "    >>> subset_patterns_iris = binner.find_patterns(iris[iris['sepal_length'] > 4.7], minimal_support_rate=.25, number_of_bins_range=(2,10), verbose=True)\n",
    "    >>> subset_best_patterns_titanic = binner.get_best_subset_patterns(full_df=titanic, subset_df=titanic[titanic['fare'] > 30], \n",
    "                                                      minimal_support_rate=.3, threshold=3.8, number_of_bins_range=(2,10))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models_ = {}\n",
    "        self.number_of_bins_range_ = (2,10)\n",
    "        self.minimal_support_rate_ = .25\n",
    "        self.threshold_ = 1.0\n",
    "        self.full_df_ = pd.DataFrame()\n",
    "        self.subset_df_ = pd.DataFrame()\n",
    "        \n",
    "    def sort_model_labels(self, model, original_labels):\n",
    "        \"\"\"Sorts labels in ascending order (cluster means) using a fit KMeans model\n",
    "        After sorting, the higher the label number, the higher the average values of the data with that label\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : a fit KMeans model\n",
    "        original_labels : the labels we want to sort \n",
    "        Returns\n",
    "        -------\n",
    "        the sorted labels\n",
    "        \"\"\"\n",
    "        label_idx = np.argsort(model.cluster_centers_.sum(axis=1))\n",
    "        lookup_table = np.zeros_like(label_idx)\n",
    "        lookup_table[label_idx] = np.arange(model.n_clusters)\n",
    "        sorted_labels = lookup_table[original_labels]\n",
    "        return sorted_labels\n",
    "        \n",
    "    def create_bins(self, column_name, df, number_of_bins_range=(2,10), replace_in_df=True, verbose=False):\n",
    "        \"\"\"An adaptive binning algorithm to convert a continuous pandas dataframe column to discrete. K means algorithm is used to create bins. \n",
    "        Mean sum of squared distances to center is used for evaluation. Knee point detection algorithm is used to select the best number of bins.\n",
    "        Parameters\n",
    "        ----------\n",
    "        column_name : the name of pandas dataframe column to convert\n",
    "        df : pandas dataframe object\n",
    "        number_of_bins_range : tuple, optional\n",
    "            The range of values for number of bins to try, the algorithm will automatically \n",
    "            select the best one from the range (default: (2,10)).\n",
    "        replace_in_df : boolean, optional\n",
    "            Whether to replace the column in the dataframe with the binned values (default: True).\n",
    "        verbose : boolean, optional\n",
    "            Whether to print out info\n",
    "        Returns\n",
    "        -------\n",
    "        the binned values \n",
    "        \"\"\"\n",
    "        # Assign value to class variable\n",
    "        self.number_of_bins_range_ = number_of_bins_range\n",
    "        \n",
    "        # Format data\n",
    "        data_to_bin = np.array(df[column_name]).reshape(-1, 1)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = KMeans(random_state=100, n_init=10, n_jobs=-1)\n",
    "        \n",
    "        # Fit the model, trying different number of bins (clusters), selecting the best number\n",
    "        elbow = KElbow(model, k=number_of_bins_range)\n",
    "        elbow.fit(data_to_bin)\n",
    "        optimal_number_of_bins = elbow.elbow_value_\n",
    "        model.set_params(n_clusters=optimal_number_of_bins)\n",
    "        model.fit(data_to_bin)\n",
    "        \n",
    "        # Get the binned value (labels)\n",
    "        model.labels_ = self.sort_model_labels(model, model.labels_)\n",
    "        \n",
    "        # Add model to class variable for all models\n",
    "        self.models_[column_name] = model\n",
    "        \n",
    "        # Replace the numeric column with the discrete values\n",
    "        if replace_in_df:\n",
    "            df[column_name] = model.labels_\n",
    "            \n",
    "        # Print out message if verbose\n",
    "        if verbose:\n",
    "            print(\"For column: {}, optimal number of bins: {}\".format(column_name, optimal_number_of_bins))\n",
    "            \n",
    "        # Return discrete values (labels)\n",
    "        return model.labels_\n",
    "    \n",
    "    \n",
    "    def find_patterns(self, df, columns_to_drop=[], minimal_support_rate=.33, number_of_bins_range=(2,10), verbose=False):\n",
    "        \"\"\"FP-growth algorithm to find patterns in the dataframe with a minimal support rate, after converting continuous features to discrete\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas dataframe object\n",
    "        columns_to_drop : list of column names to be excluding when finding patterns\n",
    "        minimal_support_rate : a float between 0 and 1 for minimum support of the itemsets returned\n",
    "        number_of_bins_range : tuple, optional\n",
    "            The range of values for number of bins to try, the algorithm will automatically \n",
    "            select the best one from the range (default: (2,10)).\n",
    "        verbose : boolean, optional\n",
    "            Whether to print out info\n",
    "        Returns\n",
    "        -------\n",
    "        all patterns found above minimal support rate\n",
    "        \"\"\"\n",
    "        # Reinitialize class models\n",
    "        self.models_ = {}\n",
    "        \n",
    "        # Assign value to class variable\n",
    "        self.minimal_support_rate_ = minimal_support_rate\n",
    "        \n",
    "        # Drop columns that are to be excluded\n",
    "        for column in columns_to_drop:\n",
    "            if column in df:\n",
    "                del df[column]\n",
    "        \n",
    "        # Iterate over each column in the dataset\n",
    "        for column in df.columns:\n",
    "            \n",
    "            # Try to see if column is numeric (continuous)\n",
    "            try:\n",
    "                data_is_numeric = np.issubdtype(df[column].dtype, np.number)\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(\"Warning: cannot create bins for column: {}\\n{}\\n\".format(column, e))\n",
    "                data_is_numeric = False\n",
    "                \n",
    "            # If column is continuous, get discrete values from binning algorithm (KMeans)\n",
    "            if data_is_numeric:\n",
    "                try:\n",
    "                    binned_values = self.create_bins(column, df, number_of_bins_range=number_of_bins_range, verbose=verbose)\n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(\"Warning: cannot create bins for column: {}\\n{}\\n\".format(column, e))\n",
    "                    \n",
    "        # Convert dataset into all discrete valued columns\n",
    "        df = pd.get_dummies(df, columns=df.columns)\n",
    "        \n",
    "        # Use FP Growth algorithm to find patterns above support rate\n",
    "        self.patterns = fpgrowth(df, min_support=minimal_support_rate, use_colnames=True)\n",
    "        \n",
    "        # Return found patterns\n",
    "        return self.patterns.sort_values('support', ascending=False)\n",
    "    \n",
    "    def transform_dataset(self, df):\n",
    "        \"\"\"Transforms a dataset, converting all continuous features to discrete using the previously fit KMeans models for labels\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas dataframe object to transform\n",
    "        Returns\n",
    "        -------\n",
    "        the transformed dataset\n",
    "        \"\"\"\n",
    "        # Iterate over each column in the dataset\n",
    "        for column in df.columns:\n",
    "            \n",
    "            # If column has been turned into a discrete column already (if there is a saved model for it)\n",
    "            if column in self.models_:\n",
    "                \n",
    "                # Get the model for the column\n",
    "                model = self.models_[column]\n",
    "                \n",
    "                # Get the discrete values using the model on the new data\n",
    "                predicted_labels = model.predict(np.array(df[column]).reshape(-1,1))\n",
    "                \n",
    "                # Sort the labels\n",
    "                sorted_labels = self.sort_model_labels(model, predicted_labels)\n",
    "                \n",
    "                # Change the values to discrete in the dataframe column\n",
    "                df[column] = sorted_labels\n",
    "                \n",
    "        # Convert dataset into all discrete valued columns\n",
    "        df = pd.get_dummies(df, columns=df.columns)\n",
    "        return df\n",
    "    \n",
    "    def get_pattern_support_rate(self, pattern, df, verbose=False):\n",
    "        \"\"\"Gets the support rate for a pattern for a new dataset\n",
    "        Parameters\n",
    "        ----------\n",
    "        pattern : a pattern object\n",
    "        df : pandas dataframe object\n",
    "        verbose : boolean, optional\n",
    "            Whether to print out info\n",
    "        Returns\n",
    "        -------\n",
    "        all patterns found above minimal support rate\n",
    "        \"\"\"\n",
    "        # Get the column names for the pattern items\n",
    "        pattern_columns = []\n",
    "        for item in pattern['itemsets']:\n",
    "            \n",
    "            # No support if column from pattern does not exist in the dataset\n",
    "            if item not in df:\n",
    "                return 0\n",
    "            pattern_columns.append(item)\n",
    "            \n",
    "        # Calculate the support rate for the full dataset\n",
    "        total_len = len(df)\n",
    "        support_num = len(pd.np.where(df[pattern_columns].eq(1).all(1))[0])\n",
    "        support_rate = support_num/total_len\n",
    "        \n",
    "        # Print out message if verbose\n",
    "        if verbose:\n",
    "            print(\"Pattern Items: {}\".format(pattern['itemsets']))\n",
    "            print(\"Original Pattern Support Rate: {}\".format(pattern['support']))\n",
    "            print(\"Dataset Pattern Support Rate: {}\".format(support_rate))\n",
    "            \n",
    "        # Return support rate for full dataset\n",
    "        return support_rate\n",
    "\n",
    "    def get_best_subset_patterns(self, full_df, subset_df, columns_to_drop=[], minimal_support_rate=.25, threshold=1.0, number_of_bins_range=(2,10), verbose=False):\n",
    "        \"\"\"Finds the patterns with the biggest difference between subset data support rate and full data support rate\n",
    "        Parameters\n",
    "        ----------\n",
    "        full_df : pandas dataframe object, full dataset to use for comparison\n",
    "        subset_df : pandas dataframe object, subset dataset to use for comparison\n",
    "        columns_to_drop : list of column names to be excluding when finding patterns\n",
    "        minimal_support_rate : float, optional (default: .25)\n",
    "            a float between 0 and 1 for minimum support of the itemsets returned\n",
    "        threshold : float, optional (default: 1.0)\n",
    "            the threshold to use for the conditon: support_rate(full data) * threshold < support_rate(subset)\n",
    "        number_of_bins_range : tuple, optional (defualt: (2,10))\n",
    "            The range of values for number of bins to try, the algorithm will automatically \n",
    "            select the best one from the range.\n",
    "        verbose : boolean, optional\n",
    "            Whether to print out info\n",
    "        Returns\n",
    "        -------\n",
    "        a dataframe with all the patterns that exceed the threshold equation for subset vs full dataset support rate\n",
    "        \"\"\"\n",
    "        # Assign value to class variable\n",
    "        self.threshold_ = threshold\n",
    "        self.full_df_ = full_df.copy()\n",
    "        self.subset_df_ = subset_df.copy()\n",
    "        \n",
    "        # Drop columns that are to be excluded\n",
    "        for column in columns_to_drop:\n",
    "            if column in self.full_df_:\n",
    "                del self.full_df_[column]\n",
    "            if column in self.subset_df_:\n",
    "                del self.subset_df_[column]\n",
    "        \n",
    "        # Find all patterns above support rate in full dataframe\n",
    "        full_df_patterns = self.find_patterns(self.full_df_, minimal_support_rate=minimal_support_rate, number_of_bins_range=number_of_bins_range, verbose=verbose)\n",
    "        subset_key_patterns = []\n",
    "        if verbose:\n",
    "            print(\"All Patterns:\")\n",
    "            \n",
    "        \n",
    "        # Transform the datasets to be of the same form\n",
    "        self.full_df_ = pd.get_dummies(self.full_df_, columns=self.full_df_.columns)\n",
    "        self.subset_df_ = self.transform_dataset(self.subset_df_)\n",
    "            \n",
    "        # Iterate over each pattern found\n",
    "        for idx,pattern in full_df_patterns.iterrows():\n",
    "            \n",
    "            # Get the subset dataset support rate for the pattern\n",
    "            subset_support_rate = self.get_pattern_support_rate(pattern, self.subset_df_)\n",
    "            full_dataset_support_rate = pattern['support']\n",
    "            \n",
    "            # If above threshold in equation, add pattern to list\n",
    "            if full_dataset_support_rate * threshold < subset_support_rate:\n",
    "                pattern_list = [item for item in pattern['itemsets']]\n",
    "                subset_key_patterns.append({\"pattern\": pattern_list, \"subset_support\": subset_support_rate, \"full_dataset_support\": full_dataset_support_rate})\n",
    "                if verbose:\n",
    "                    print(pattern['itemsets'])\n",
    "                \n",
    "        # Sort best patterns\n",
    "        subset_key_patterns = sorted(subset_key_patterns, key=lambda x: x['subset_support'] / x['full_dataset_support'], reverse=True)\n",
    "        \n",
    "        # Return dataframe with all pattern information\n",
    "        return pd.DataFrame(subset_key_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hr.csv\")\n",
    "binner = Binner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>subset_support</th>\n",
       "      <th>full_dataset_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[StandardHours_80, Over18_Y, YearsAtCompany_0,...</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[EmployeeCount_1, YearsAtCompany_0, MaritalSta...</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[StockOptionLevel_0, YearsAtCompany_0, Marital...</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Over18_Y, YearsAtCompany_0, MaritalStatus_Sin...</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[StandardHours_80, YearsAtCompany_0, MaritalSt...</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.202041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>[StandardHours_80, JobLevel_1, MonthlyIncome_0...</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>0.213605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>[JobLevel_1, MonthlyIncome_0, YearsAtCompany_0...</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>0.213605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>[JobLevel_1, MonthlyIncome_0, YearsAtCompany_0...</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>0.213605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>[StandardHours_80, JobLevel_1, MonthlyIncome_0...</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>0.213605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>[BusinessTravel_Travel_Rarely, JobLevel_1, Mon...</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>0.213605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pattern  subset_support  \\\n",
       "0    [StandardHours_80, Over18_Y, YearsAtCompany_0,...        0.392405   \n",
       "1    [EmployeeCount_1, YearsAtCompany_0, MaritalSta...        0.392405   \n",
       "2    [StockOptionLevel_0, YearsAtCompany_0, Marital...        0.392405   \n",
       "3    [Over18_Y, YearsAtCompany_0, MaritalStatus_Sin...        0.392405   \n",
       "4    [StandardHours_80, YearsAtCompany_0, MaritalSt...        0.392405   \n",
       "..                                                 ...             ...   \n",
       "595  [StandardHours_80, JobLevel_1, MonthlyIncome_0...        0.320675   \n",
       "596  [JobLevel_1, MonthlyIncome_0, YearsAtCompany_0...        0.320675   \n",
       "597  [JobLevel_1, MonthlyIncome_0, YearsAtCompany_0...        0.320675   \n",
       "598  [StandardHours_80, JobLevel_1, MonthlyIncome_0...        0.320675   \n",
       "599  [BusinessTravel_Travel_Rarely, JobLevel_1, Mon...        0.320675   \n",
       "\n",
       "     full_dataset_support  \n",
       "0                0.202041  \n",
       "1                0.202041  \n",
       "2                0.202041  \n",
       "3                0.202041  \n",
       "4                0.202041  \n",
       "..                    ...  \n",
       "595              0.213605  \n",
       "596              0.213605  \n",
       "597              0.213605  \n",
       "598              0.213605  \n",
       "599              0.213605  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.2 s\n"
     ]
    }
   ],
   "source": [
    "subset_key_patterns_hr_df = binner.get_best_subset_patterns(full_df=df, subset_df=df[df['Attrition'] == \"Yes\"], \n",
    "                                                  columns_to_drop=['Attrition'], minimal_support_rate=.2, threshold=1.5, number_of_bins_range=(2,10))\n",
    "subset_key_patterns_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "2     1\n",
       "14    0\n",
       "21    1\n",
       "24    0\n",
       "26    1\n",
       "33    1\n",
       "34    1\n",
       "36    1\n",
       "42    0\n",
       "45    0\n",
       "50    0\n",
       "Name: MonthlyRate_0, dtype: uint8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "binner.subset_df_.MonthlyRate_0[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    1\n",
       "18    0\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    1\n",
       "27    0\n",
       "28    1\n",
       "29    0\n",
       "30    1\n",
       "31    0\n",
       "32    0\n",
       "33    1\n",
       "34    1\n",
       "35    0\n",
       "36    1\n",
       "37    0\n",
       "38    0\n",
       "39    1\n",
       "40    0\n",
       "41    0\n",
       "42    0\n",
       "43    1\n",
       "44    0\n",
       "45    0\n",
       "46    0\n",
       "47    0\n",
       "48    0\n",
       "49    1\n",
       "Name: MonthlyRate_0, dtype: uint8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.31 ms\n"
     ]
    }
   ],
   "source": [
    "binner.full_df_.MonthlyRate_0[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn continuous column into discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column: petal_length, optimal number of bins: 4\n",
      "time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "binned_values_iris_petal_length = binner.create_bins('petal_length', iris, number_of_bins_range=(2,10), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best patterns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column: sepal_width, optimal number of bins: 4\n",
      "Warning: cannot create bins for column: petal_length\n",
      "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by check_pairwise_arrays.\n",
      "\n",
      "For column: petal_width, optimal number of bins: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>(sepal_width_1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>(petal_width_1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>(species_versicolor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>(species_virginica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345324</td>\n",
       "      <td>(petal_width_2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.345324</td>\n",
       "      <td>(petal_width_1, species_versicolor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.330935</td>\n",
       "      <td>(petal_width_2, species_virginica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.323741</td>\n",
       "      <td>(petal_length_2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(species_setosa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(petal_width_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(petal_length_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(species_setosa, petal_width_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(petal_length_0, petal_width_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(species_setosa, petal_length_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>(species_setosa, petal_length_0, petal_width_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>(sepal_width_2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support                                         itemsets\n",
       "4   0.474820                                  (sepal_width_1)\n",
       "5   0.374101                                  (petal_width_1)\n",
       "6   0.359712                             (species_versicolor)\n",
       "9   0.359712                              (species_virginica)\n",
       "8   0.345324                                  (petal_width_2)\n",
       "14  0.345324              (petal_width_1, species_versicolor)\n",
       "15  0.330935               (petal_width_2, species_virginica)\n",
       "7   0.323741                                 (petal_length_2)\n",
       "0   0.280576                                 (species_setosa)\n",
       "1   0.280576                                  (petal_width_0)\n",
       "2   0.280576                                 (petal_length_0)\n",
       "10  0.280576                  (species_setosa, petal_width_0)\n",
       "11  0.280576                  (petal_length_0, petal_width_0)\n",
       "12  0.280576                 (species_setosa, petal_length_0)\n",
       "13  0.280576  (species_setosa, petal_length_0, petal_width_0)\n",
       "3   0.251799                                  (sepal_width_2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "subset_patterns_iris = binner.find_patterns(iris[iris['sepal_length'] > 4.7], columns_to_drop=['sepal_length'], minimal_support_rate=.25, number_of_bins_range=(2,10), verbose=True)\n",
    "subset_patterns_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best patterns when comparing subset to full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>subset_support</th>\n",
       "      <th>full_dataset_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[pclass_1, class_First]</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[pclass_1]</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[class_First]</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[survived_1, alive_yes, alone_False]</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>0.200898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[survived_1, alone_False]</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>0.200898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>[parch_0, sex_female]</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.217733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>[parch_0, adult_male_False]</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.219978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>[alive_yes, sibsp_0]</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.235690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>[survived_1, alive_yes, sibsp_0]</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.235690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>[survived_1, sibsp_0]</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.235690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pattern  subset_support  full_dataset_support\n",
       "0                [pclass_1, class_First]        0.722222              0.242424\n",
       "1                             [pclass_1]        0.722222              0.242424\n",
       "2                          [class_First]        0.722222              0.242424\n",
       "3   [survived_1, alive_yes, alone_False]        0.393162              0.200898\n",
       "4              [survived_1, alone_False]        0.393162              0.200898\n",
       "..                                   ...             ...                   ...\n",
       "72                 [parch_0, sex_female]        0.256410              0.217733\n",
       "73           [parch_0, adult_male_False]        0.256410              0.219978\n",
       "74                  [alive_yes, sibsp_0]        0.273504              0.235690\n",
       "75      [survived_1, alive_yes, sibsp_0]        0.273504              0.235690\n",
       "76                 [survived_1, sibsp_0]        0.273504              0.235690\n",
       "\n",
       "[77 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "subset_key_patterns_titanic = binner.get_best_subset_patterns(full_df=titanic, subset_df=titanic[titanic['fare'] > 30], \n",
    "                                                  columns_to_drop=['fare'], minimal_support_rate=.2, threshold=1, number_of_bins_range=(2,10))\n",
    "subset_key_patterns_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>subset_support</th>\n",
       "      <th>full_dataset_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[petal_width_0]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[petal_length_0]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[petal_length_0, petal_width_0]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[petal_length_0, sepal_length_0]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[petal_width_0, sepal_length_0]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[petal_length_0, petal_width_0, sepal_length_0]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[sepal_length_0]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[sepal_width_2]</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pattern  subset_support  \\\n",
       "0                                  [petal_width_0]            1.00   \n",
       "1                                 [petal_length_0]            1.00   \n",
       "2                  [petal_length_0, petal_width_0]            1.00   \n",
       "3                 [petal_length_0, sepal_length_0]            0.78   \n",
       "4                  [petal_width_0, sepal_length_0]            0.78   \n",
       "5  [petal_length_0, petal_width_0, sepal_length_0]            0.78   \n",
       "6                                 [sepal_length_0]            0.78   \n",
       "7                                  [sepal_width_2]            0.50   \n",
       "\n",
       "   full_dataset_support  \n",
       "0              0.333333  \n",
       "1              0.333333  \n",
       "2              0.333333  \n",
       "3              0.260000  \n",
       "4              0.260000  \n",
       "5              0.260000  \n",
       "6              0.300000  \n",
       "7              0.273333  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "subset_key_patterns = binner.get_best_subset_patterns(full_df=iris, subset_df=iris[iris['species'] == 'setosa'], \n",
    "                                                      columns_to_drop=['species'], minimal_support_rate=.25, threshold=1.45, number_of_bins_range=(2,10))\n",
    "subset_key_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column: sepal_width, optimal number of bins: 4\n",
      "Warning: cannot create bins for column: petal_length\n",
      "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by check_pairwise_arrays.\n",
      "\n",
      "For column: petal_width, optimal number of bins: 3\n",
      "All Patterns:\n",
      "frozenset({'petal_width_1'})\n",
      "frozenset({'species_versicolor'})\n",
      "frozenset({'species_virginica'})\n",
      "frozenset({'petal_width_2'})\n",
      "frozenset({'petal_width_1', 'species_versicolor'})\n",
      "frozenset({'petal_width_2', 'species_virginica'})\n",
      "frozenset({'petal_length_2'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>subset_support</th>\n",
       "      <th>full_dataset_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[petal_width_2, species_virginica]</td>\n",
       "      <td>0.330935</td>\n",
       "      <td>0.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[petal_width_1]</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[species_versicolor]</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[species_virginica]</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[petal_width_2]</td>\n",
       "      <td>0.345324</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[petal_width_1, species_versicolor]</td>\n",
       "      <td>0.345324</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[petal_length_2]</td>\n",
       "      <td>0.323741</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pattern  subset_support  full_dataset_support\n",
       "0   [petal_width_2, species_virginica]        0.330935              0.306667\n",
       "1                      [petal_width_1]        0.374101              0.346667\n",
       "2                 [species_versicolor]        0.359712              0.333333\n",
       "3                  [species_virginica]        0.359712              0.333333\n",
       "4                      [petal_width_2]        0.345324              0.320000\n",
       "5  [petal_width_1, species_versicolor]        0.345324              0.320000\n",
       "6                     [petal_length_2]        0.323741              0.300000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 858 ms\n"
     ]
    }
   ],
   "source": [
    "subset_key_patterns = binner.get_best_subset_patterns(full_df=iris, subset_df=iris[iris['sepal_length'] > 4.7], \n",
    "                                                      columns_to_drop=['sepal_length'], minimal_support_rate=.25, threshold=1.07, number_of_bins_range=(2,10), verbose=True)\n",
    "subset_key_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
